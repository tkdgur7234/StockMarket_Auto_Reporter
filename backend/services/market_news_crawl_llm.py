# backend/services/market_new_crawl.py

import feedparser
import os
from openai import OpenAI
from dotenv import load_dotenv
import json
import re
from html import unescape
from datetime import datetime
import pytz

load_dotenv()

# --- [ì „ëµ ìˆ˜ì •] Positive Filter ìœ„ì£¼ì˜ ì •ë°€ ì¿¼ë¦¬ ---
# 2. Positive Filter ê°•í™”: ì§€ìˆ˜ëª… + ë§ˆê°í‚¤ì›Œë“œ(Close/Ends) í•„ìˆ˜ í¬í•¨(AND)
# 3. ì‹œê°„ ë‹¨ì¶•: when:12h (ìµœê·¼ 12ì‹œê°„)ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ 'ì–´ì œ ì•„ì¹¨' ë‰´ìŠ¤ ë°°ì œ

TRACKS = [
    {
        # [Track A] ì¥ ë§ˆê° ì‹œí™© (Market Wrap)
        # S&P 500 ë˜ëŠ” Nasdaqì´ ì œëª©ì— ê¼­ ìˆì–´ì•¼ í•˜ê³ , 'Close'ë‚˜ 'Wrap' ê°™ì€ ë§ˆê° ë‹¨ì–´ê°€ í•„ìˆ˜
        "name": "Track A: Market Wrap (í˜„ìƒ)",
        "url": 'https://news.google.com/rss/search?q=("S%26P+500"+OR+"Nasdaq")+AND+("close"+OR+"ends"+OR+"settles"+OR+"wrap")+when:12h&hl=en-US&gl=US&ceid=US:en',
        "limit": 2
    },
    {
        # [Track B] ë“±ë½ ì›ì¸ (Why it moved)
        # "Stocks"ë‚˜ "Wall Street"ê°€ ì£¼ì–´ì´ê³ , ì¸ê³¼ê´€ê³„(due to, as)ë¥¼ ì„¤ëª…í•˜ëŠ” ê¸°ì‚¬
        "name": "Track B: Why it moved (ì›ì¸)",
        "url": 'https://news.google.com/rss/search?q=("US+stocks"+OR+"Wall+Street")+AND+("rise"+OR+"fall"+OR+"climb"+OR+"drop")+AND+("due+to"+OR+"as"+OR+"on")+when:12h&hl=en-US&gl=US&ceid=US:en',
        "limit": 4
    },
    {
        # [Track C] ì£¼ë„ì£¼ (Movers)
        # 'Active stocks' ë“±ìœ¼ë¡œ ê²€ìƒ‰í•˜ë˜, Track A/Bì—ì„œ ë‹¤ë£¬ ë‚´ìš©ê³¼ ê²¹ì¹˜ì§€ ì•Šê²Œ ê°œë³„ ì¢…ëª© ìœ„ì£¼
        "name": "Track C: Active Movers (ì£¼ë„ì£¼)",
        "url": 'https://news.google.com/rss/search?q=("S%26P+500"+OR+"Nasdaq")+AND+("biggest+movers"+OR+"active+stocks")+when:12h&hl=en-US&gl=US&ceid=US:en',
        "limit": 2
    }
]

def clean_html(raw_html):
    """HTML íƒœê·¸ ì œê±°"""
    cleanr = re.compile('<.*?>')
    cleantext = re.sub(cleanr, '', raw_html)
    return unescape(cleantext).strip()

def convert_pubdate_to_kst(pub_date_str):
    """RSS ë‚ ì§œ(GMT) -> KST ë³€í™˜"""
    try:
        dt_obj = datetime.strptime(pub_date_str, "%a, %d %b %Y %H:%M:%S %Z")
        dt_utc = dt_obj.replace(tzinfo=pytz.utc)
        kst_tz = pytz.timezone('Asia/Seoul')
        return dt_utc.astimezone(kst_tz).strftime("%Y-%m-%d %H:%M:%S KST")
    except Exception:
        return pub_date_str

def get_market_news():
    """
    3-Track ì „ëµ ìˆ˜ì§‘ (Positive Filter ì ìš©)
    """
    all_articles = []
    seen_links = set()

    print("ğŸš€ 3-Track ë¯¸êµ­ ì¦ì‹œ ë‰´ìŠ¤ í¬ë¡¤ë§ (Positive Filter)...")

    try:
        for track in TRACKS:
            feed = feedparser.parse(track["url"])
            count = 0
            
            for entry in feed.entries:
                if count >= track["limit"]:
                    break
                
                # ì¤‘ë³µ URL ì²´í¬
                if entry.link in seen_links:
                    continue
                seen_links.add(entry.link)
                
                # ë‚ ì§œ ë³€í™˜
                pub_date = entry.published if 'published' in entry else ""
                kst_date = convert_pubdate_to_kst(pub_date)

                # Description ì „ì²˜ë¦¬
                raw_desc = entry.description if 'description' in entry else ""
                clean_desc = clean_html(raw_desc)
                summary_text = clean_desc if len(clean_desc) > 20 else entry.title

                all_articles.append({
                    "track": track["name"],
                    "title": entry.title,
                    "link": entry.link,
                    "pub_date": kst_date,
                    "summary_raw": summary_text
                })
                count += 1
            
            print(f"âœ… {track['name']} - {count}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")

        if not all_articles:
            return {"status": "error", "message": "No news found"}

        # AI ë¶„ì„ ìš”ì²­
        ai_result = analyze_with_upstage_summary(all_articles)
        
        return {
            "status": "success",
            "market_summary": ai_result.get("market_summary", "ìš”ì•½ ìƒì„± ì‹¤íŒ¨"),
            "news_list": ai_result.get("news_list", all_articles)
        }

    except Exception as e:
        print(f"News Crawl Error: {e}")
        return {"status": "error", "message": str(e)}

def analyze_with_upstage_summary(articles):
    """
    Upstage Solar API: ì¢…í•© ìš”ì•½ + ë²ˆì—­
    """
    api_key = os.getenv("UPSTAGE_API_KEY")
    if not api_key:
        print("âš ï¸ Upstage API Key missing")
        return {"market_summary": "API Key ì—†ìŒ", "news_list": articles}

    client = OpenAI(
        api_key=api_key,
        base_url="https://api.upstage.ai/v1/solar"
    )

    context_text = ""
    for i, a in enumerate(articles):
        context_text += f"[News {i+1}] ({a['track']}) - {a['pub_date']}\nTitle: {a['title']}\nContent: {a['summary_raw'][:300]}\n\n"

    # [í”„ë¡¬í”„íŠ¸] 'Market Close' ì‹œì ì„ ëª…ì‹œì ìœ¼ë¡œ ê°•ì¡°
    system_prompt = """
    You are an expert AI Financial Analyst specializing in the US Stock Market. 
    Your goal is to write a 'Daily Market Briefing' for Korean investors.

    Task 1: Market Driver Synthesis
    - Focus on the 'Market Close' results from the provided news.
    - Identify the primary reason for the market's movement (e.g., S&P 500 rose due to tech earnings).
    - Write a cohesive paragraph (3-4 sentences) **in Korean**.

    Task 2: Headline Translation
    - Translate the titles into professional Korean business language.

    Output MUST be in JSON format:
    {
        "market_summary": "í•œêµ­ì–´ ìš”ì•½...",
        "news_list": [
            {"korean_title": "...", "original_title": "..."}
        ]
    }
    """

    try:
        response = client.chat.completions.create(
            model="solar-1-mini-chat",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"Here is the collected news data:\n{context_text}"}
            ],
            temperature=0.1
        )
        
        content = response.choices[0].message.content
        cleaned_content = content.replace("```json", "").replace("```", "").strip()
        ai_data = json.loads(cleaned_content)
        
        final_news_list = []
        ai_list = ai_data.get("news_list", [])
        
        for i, article in enumerate(articles):
            korean_title = article["title"]
            if i < len(ai_list):
                korean_title = ai_list[i].get("korean_title", article["title"])
            
            final_news_list.append({
                "title": korean_title,
                "original_title": article["title"],
                "link": article["link"],
                "track": article["track"],
                "pub_date": article["pub_date"]
            })

        return {
            "market_summary": ai_data.get("market_summary", "-"),
            "news_list": final_news_list
        }

    except Exception as e:
        print(f"Upstage AI Logic Error: {e}")
        return {"market_summary": "AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ", "news_list": articles}